{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"GitLab/","title":"Index","text":""},{"location":"GitLab/#access-token-expiration","title":"Access Token Expiration","text":"<p>Interesting note about gitlab, starting in versions 16.0, access tokens will be forced to have an expiry date.</p> <p>Supposedly, this can be circumvented by using certain gitlab versions</p>"},{"location":"GitLab/Helm%20Installation/Gitaly/","title":"Gitaly","text":""},{"location":"GitLab/Helm%20Installation/Gitaly/#gitaly-on-kubernetes","title":"Gitaly On Kubernetes","text":"<p>Gitaly cannot be deployed on Kubernetes in an HA manner. What you have to do is actually deploy it as a Gitaly Cluster.</p>"},{"location":"GitLab/Helm%20Installation/Gitaly/#migrating-for-gitaly-on-kubernetes-to-cluster","title":"Migrating for Gitaly on Kubernetes to Cluster","text":"<p>In case you want to move all of the data from a single pod to a cluster, or just generally between clusters (Why? you can easily swap the nodes, and they have to remain in the same versions anyways)</p> <p>The guide is helpful, but</p> <p>You should remember: 1. Moving causes no real disruption in GitLab, it might cause a certain repository to be unavailable for a couple of moments. No need for downtime. 2. If trying to move from Kubernetes, you need a way to expose the service to the outside world, since the gitaly cluster will attempt to communicate with it. You can create a LoadBalancer service, and make gitlab communicate with gitaly through it, rather than the internal address</p>"},{"location":"GitLab/Operator%20Installation/","title":"Index","text":""},{"location":"GitLab/Operator%20Installation/#operator","title":"Operator","text":"<p>Any installation that uses routes will be unable to use ssh clones</p>"},{"location":"OpenShift/securityContext/","title":"securityContext","text":"<p>If you have weird errors writing into PVCs in OpenShift, you probably need to update your securityContext:</p> <pre><code>securityContext:\n    fsGroups: 1002480000\n    seLinuxOptions:\n        level: s0:c50,c15\n</code></pre> <p>What does this mean? Well this is the more complicated part.</p> <p>Kinda weird that fsGroups requires that, since usually, mounted pvcs are owned by the root group, which our user should belong to (at least, according to the docs)</p> <p>fsGroups is rather easy to explain, This is a linux user number that OpenShift permits. The question is what numbers are ok. Is any number that is higher than 1000000000 ok? Or does the range matter?</p> <p>The seLinuxOptions, is the part I really cant explain, however.</p> <p>OpenShift provides the following default SCCs:</p> <p>anyuid</p> <p>hostaccess</p> <p>hostmount-anyuid</p> <p>hostnetwork</p> <p>hostnetwork-v2</p> <p>lvms-topolvm-node</p> <p>lvms-vgmanager</p> <p>machine-api-termination-handler</p> <p>node-exporter</p> <p>nonroot</p> <p>nonroot-v2</p> <p>privileged</p> <p>restricted</p> <p>restricted-v2</p>"},{"location":"SELinux/","title":"Troubleshoot SELinux Issues","text":"<p>When applications unexpectedly fail to work due to SELinux access denials, methods and tools are available to resolve these issues. It is helpful to start by understanding some fundamental concepts and behaviors when SELinux is enabled.</p> <p>SELinux consists of targeted policies that explicitly define allowable actions.</p> <p>A policy entry defines a labeled process and a labeled resource that interact.</p> <p>The policy states the process type, and the file or port context, by using labels.</p> <p>The policy entry defines one process type, one resource label, and the explicit action to allow.</p> <p>An action can be a system call, a kernel function, or another specific programming routine.</p> <p>If no entry is created for a specific process-resource-action relationship, then the action is denied.</p> <p>When an action is denied, the attempt is logged with useful context information.</p> <p>Red Hat Enterprise Linux provides a stable targeted SELinux policy for almost every service in the distribution. Therefore, it is unusual to have SELinux access problems with common RHEL services when they are configured correctly. SELinux access problems occur when services are implemented incorrectly, or when new applications have incomplete policies. Consider these troubleshooting concepts before making broad SELinux configuration changes.</p> <p>Most access denials indicate that SELinux is working correctly by blocking improper actions.</p> <p>Evaluating denied actions requires some familiarity with normal, expected service actions.</p> <p>The most common SELinux issue is an incorrect context on new, copied, or moved files.</p> <p>File contexts can be fixed when an existing policy references their location.</p> <p>Optional Boolean policy features are documented in the _selinux man pages.</p> <p>Implementing Boolean features generally requires setting additional non-SELinux configuration.</p> <p>SELinux policies do not replace or circumvent file permissions or access control list restrictions.</p> <p>When a common application or service fails, and the service is known to have a working SELinux policy, first see the service's _selinux man page to verify the correct context type label. View the affected process and file attributes to verify that the correct labels are set.</p>"},{"location":"Useful%20Commands/","title":"Index","text":""},{"location":"Useful%20Commands/#kubernetes","title":"Kubernetes","text":"<p><code>kubectl get pods | grep Error | awk {'print $1'} | xargs oc delete pods</code></p>"},{"location":"Useful%20Commands/#docker","title":"Docker","text":"<p><code>docker rmi $(docker images -f \"dangling=true\" -q)</code></p>"},{"location":"Useful%20Commands/#certificates","title":"Certificates","text":"<p><code>open_ssl s_client -connect &lt;your_url&gt;:8082 -showcerts &lt; /dev/null &gt; &lt;your_url&gt;.crt</code></p>"},{"location":"nushell/","title":"Index","text":"<p>So the <code>open</code> command can be piped to interact with the output, for example:</p> <p><code>open ~/.ss/rsa | xclip -sel c</code></p> <p>Since data is outputted into tables, you need to know how to take data from them, for example:</p> <p><code>oc get secret -n openshift-gitops repo-1834075916 -o yaml | from yaml | select data.sshPrivateKey</code></p> <p>If you wanna take the data, you can just</p> <p><code>oc get secret -n openshift-gitops repo-1834075916 -o yaml | from yaml | get data.sshPrivateKey</code></p>"},{"location":"rdhd/Installation/","title":"Installation","text":"<p>There are two methods of installation:</p> <ol> <li>Helm Chart</li> <li>Operator</li> </ol>"},{"location":"rdhd/Installation/#opertator","title":"Opertator","text":"<p>As I am writing this message, the operator version is 1.4.1, provided by Red Hat officially, and requires a subscription</p> <p>So far, I've used this guide - https://developers.redhat.com/learning/learn:deploying-and-troubleshooting-red-hat-developer-hub-openshift-practical-guide/resource/resource:deploying-and-troubleshooting-red-hat-developer-hub-openshift-practical-guide:prerequisites-and-step-by-step-guide</p> <p>For operator installation</p>"},{"location":"ssh/general-tips/","title":"General tips","text":"<p>If you want to connect to a VM using a provided ssh key, you need to:</p> <ol> <li>Use <code>ssh-add</code> to the fullpath of your key</li> <li>Use <code>ssh -i &lt;your_key&gt;</code></li> </ol> <p>If you want to add your own ssh ket to a vm, you use</p> <p><code>ssh-copy-id -i ~/.ssh/some_public_key.pub user@host</code></p> <p>if you use the default key, you won't need to add <code>-i</code> on later logins, but you can use ssh profile to set this to be automatic as well</p> <p>can't use ssh key for some reason? perhaps the host does not allow it. You can use <code>ssh -v</code> for more information.</p> <p>Cool example of ssh-config:</p> <pre><code>[user@host ~]$ cat ~/.ssh/config\nhost servera\n     HostName                      servera.example.com\n     User                          usera\n     IdentityFile                  ~/.ssh/id_rsa_servera\n\nhost serverb\n     HostName                      serverb.example.com\n     User                          userb\n     IdentityFile                  ~/.ssh/id_rsa_serverb\n</code></pre> <p>Do you get a host identification error but you are sure everything is ok?</p> <p>you can use this:</p> <p><code>alias ssh0='ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no -o LogLevel=ERROR'</code></p> <p>to ignore that part of ssh</p>"}]}